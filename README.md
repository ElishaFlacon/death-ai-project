<h1> 
     üîé –†–∞—Å–ø–æ–∑–Ω–æ–≤–∞—Ç–µ–ª—å —ç–º–æ—Ü–∏–π
</h1>

<h3>
–ü—Ä–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —ç–º–æ—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫ —Å –≤–µ–±–∫–∞–º–µ—Ä—ã
</h3>


</br>



<h2>
  üõ†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞:
</h2>

- deepface==0.0.75
- opencv-python==4.6.0.66



</br>



<h2>
  üöÄ –ó–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:
</h2>

- git clone https://github.com/ElishaFlacon/emotions-recognizer.git
- cd emotions-recognizer
- python -m venv <venv_name>
- source <venv_name>/Scripts/activate (linux) or <venv_name>/Scripts/activate (windows)
- pip install -r ./requirements.txt
- –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–∫–∞—á–∞—Ç—å haarcascade_frontalface_default.xml –∏–∑ <a href="https://github.com/opencv/opencv/tree/4.x/data/haarcascades">haarcascades</a>, –ø–æ–ª—Å–µ —á–µ–≥–æ –∑–∞–ø–∏—Ö–Ω—É—Ç—å, –ª–∏–±–æ –≤ –ø—Ä–æ–µ–∫—Ç –∏ –∏–∑–º–µ–Ω–∏—Ç—å –ø—É—Ç—å –¥–æ –Ω–µ–≥–æ (9 —Å—Ç—Ä–æ–∫–∞), –ª–∏–±–æ –≤ –ø–∞–ø–∫—É —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π <venv_name>/Lib/site-packages/cv2/data. –í–æ –≤—Ç—Ä–æ—Ä–æ–º —Å–ª—É—á–∞–µ –∫–æ–¥ –Ω–µ –º–µ–Ω—è–µ–º
- –∏–∑–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã
- python main.py
<h3>
    –ó–∞–ø—É—Å–∫–∞–µ–º, –Ω–µ —Ä–∞–±–æ—Ç–µ—Ç, —É—Ä–∞! üóøüö¨
</h3>


</br>



<h2>
 üì∫ –î–µ–º–æ:
</h2>

<p align="center">
<img src="https://user-images.githubusercontent.com/83610362/233321618-fc4738d3-4a2b-4160-a0af-3cf78c28cf74.png" alt="demo not working"/>
</p>




</br>



<h2>
‚ö° –ù–µ–º–Ω–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:
</h2>

- –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –ø—Ä–æ–µ–∫—Ç –º–µ—Ä—Ç–≤, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω!
- P.S. –í—Å–µ –±–∞–≥–∏ –∏ –Ω–µ–¥–æ—á–µ—Ç—ã - —ç—Ç–æ —Ñ–∏—á–∏






<br/>
<br/>
<br/>
<br/>
<br/>
<br/>



<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=d179b8&height=64&section=footer"/>
</p>
